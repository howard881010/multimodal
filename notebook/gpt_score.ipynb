{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('../')\n",
    "from src.utils import find_text_parts, split_text\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from evaluator.gpt_evaluator import GPT4Semantic, GPT4Accuracy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(window_size, unit, dataset, model_type, text_key_name, num_key_name):\n",
    "    output_dir = f\"/home/ubuntu/multimodal/Data/{dataset}-GPT4-Evaluation/{model_type}/{window_size}{unit}\"\n",
    "    filename = \"processed.csv\"\n",
    "    num_pattern = fr\"{unit}_\\d+_{num_key_name}: '([\\d.]+)'\"\n",
    "    text_pattern =fr'({unit}_\\d+_date:\\s*\\S+\\s+{unit}_\\d+_{text_key_name}:.*?)(?=\\s{unit}_\\d+_date|\\Z)'\n",
    "    hf_dataset = f\"Howard881010/{dataset}-{window_size}{unit}\" + (\"-mixed\" if model_type.startswith(\"textTime2textTime\") else \"\") +  \"-inContext\"\n",
    "\n",
    "    data_all = load_dataset(hf_dataset)\n",
    "    data = pd.DataFrame(data_all['test'])\n",
    "\n",
    "    output_texts = data['output'].apply(lambda x: find_text_parts(x, num_pattern)).apply(lambda x: split_text(x, text_pattern)).to_list()\n",
    "    pred_texts = data['pred_output'].apply(lambda x: find_text_parts(x, num_pattern)).apply(lambda x: split_text(x, text_pattern)).to_list()\n",
    "    for idx, pred_text in enumerate(pred_texts):\n",
    "        if len(pred_text) > window_size:\n",
    "            pred_texts[idx] = pred_text[:window_size]\n",
    "        while len(pred_text) < window_size:\n",
    "            pred_texts[idx].append(None)\n",
    "\n",
    "    output_texts = np.reshape(output_texts, -1)\n",
    "    pred_texts = np.reshape(pred_texts, -1)\n",
    "\n",
    "    results = pd.DataFrame({\"output_text\": output_texts, \"pred_text\": pred_texts})\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    results.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_completion(job_id, processor, poll_interval=100):\n",
    "    status = processor.check_status(job_id)\n",
    "    while status.status not in [\"completed\", \"failed\"]:\n",
    "        print(f\"Current status: {status}. Waiting for {poll_interval} seconds...\")\n",
    "        time.sleep(poll_interval)\n",
    "        status = processor.check_status(job_id)\n",
    "    return status.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4 semantic & GPT4 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(window_size, unit, dataset, model_type, text_key_name, num_key_name):\n",
    "    processData(window_size, unit, dataset, model_type, text_key_name, num_key_name)\n",
    "\n",
    "    gpt4semantic = GPT4Semantic()\n",
    "\n",
    "    results_dir = f\"/home/ubuntu/multimodal/Data/{dataset}-GPT4-Evaluation/{model_type}/{window_size}{unit}\"\n",
    "    data = pd.read_csv(f\"/home/ubuntu/multimodal/Data/{dataset}-GPT4-Evaluation/{model_type}/{window_size}{unit}/processed.csv\")\n",
    "\n",
    "    jsonl_path = os.path.join(results_dir, \"batch.jsonl\")\n",
    "    semantic_output_path = os.path.join(results_dir, \"semantic.txt\")\n",
    "\n",
    "    semantic_batch_object_id = gpt4semantic.create_and_run_batch_job(data, jsonl_path, output_text_column=\"output_text\",\n",
    "                                    pred_text_column=\"pred_text\")\n",
    "\n",
    "    job_status = wait_for_completion(semantic_batch_object_id, gpt4semantic)\n",
    "\n",
    "    if job_status == \"completed\":\n",
    "        print(\"Batch job completed successfully!\")\n",
    "        semantic_outputs = gpt4semantic.check_status_and_parse(semantic_batch_object_id , semantic_output_path)\n",
    "        semantic_score, count_none = gpt4semantic.calculate_metrics(semantic_outputs)\n",
    "\n",
    "\n",
    "    gpt4accuracy = GPT4Accuracy()\n",
    "    accuracy_output_path = os.path.join(results_dir, \"accuracy.txt\")\n",
    "    accuracy_batch_object_id = gpt4accuracy.create_and_run_batch_job(data, jsonl_path, output_text_column=\"output_text\",\n",
    "                                    pred_text_column=\"pred_text\")\n",
    "\n",
    "    job_status = wait_for_completion(accuracy_batch_object_id, gpt4accuracy)\n",
    "    if job_status == \"completed\":\n",
    "        print(\"Batch job completed successfully!\")\n",
    "        accuracy_outputs = gpt4accuracy.check_status_and_parse(accuracy_batch_object_id, accuracy_output_path)\n",
    "        precisions, recalls, f1_scores = gpt4accuracy.calculate_metrics(accuracy_outputs)\n",
    "\n",
    "    results = {\"semantic_score\": semantic_score, \"count_none\": count_none, \"precisions\": precisions, \"recalls\": recalls, \"f1_scores\": f1_scores}\n",
    "    results = pd.DataFrame.from_dict(results, orient=\"index\").T\n",
    "    results.to_csv(os.path.join(results_dir, \"results.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ffad48f5d6418395a665cb9449609a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfe4f53415346e5830fadbf34517aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0889164921b24435bacac98ff4b6bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/821k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f65a6e828a4a57bd351ca3e746eb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2290b92840a64c05b041f8ce083b0ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2888 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee2fbc105374f44ba46f3f53754b300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982b62cdc4944ff80bef5074e498546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch job created with batch_object_id \n",
      " batch_kVyaTz2SrCumFQluM8gLqotu\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=922, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2034, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=None, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2153, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=1725035288, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2172, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_kVyaTz2SrCumFQluM8gLqotu', completion_window='24h', created_at=1725034288, endpoint='/v1/chat/completions', input_file_id='file-KUlXTpoMIw0Iu5aPlsnpeSIt', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725120688, failed_at=None, finalizing_at=1725035288, in_progress_at=1725034289, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2172, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Batch job completed successfully!\n",
      "batch job created with batch_object_id \n",
      " batch_rpF47cIfbBAo2JvdBRWg2hLZ\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=760, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=1443, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2144, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=None, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2171, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Current status: Batch(id='batch_rpF47cIfbBAo2JvdBRWg2hLZ', completion_window='24h', created_at=1725035493, endpoint='/v1/chat/completions', input_file_id='file-BlcAhnC8byh2jXKOQvKQsqQ6', object='batch', status='finalizing', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725121893, failed_at=None, finalizing_at=1725036654, in_progress_at=1725035495, metadata={'description': 'Multimodal Forecasting'}, output_file_id=None, request_counts=BatchRequestCounts(completed=2172, failed=0, total=2172)). Waiting for 100 seconds...\n",
      "Batch job completed successfully!\n"
     ]
    }
   ],
   "source": [
    "unit = \"day\"\n",
    "dataset = \"climate\"\n",
    "text_key_name = \"weather_forecast\"\n",
    "num_key_name = \"temp\"\n",
    "model_type = \"textTime2textTime-inContext\"\n",
    "for window_size in [6]:\n",
    "    calculate_metrics(window_size, unit, dataset, model_type, text_key_name, num_key_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
