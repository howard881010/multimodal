{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# os.sys.path.append(\"/data/kai/forecasting/multimodal/financial/src\")\n",
    "# from utils import download_raw_texts_from_urls, save_text_to, load_text_from \n",
    "from glob import glob\n",
    "from tqdm import trange  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob(\"/data/kai/forecasting/data/raw_v0.2/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_words = [\n",
    "    \"thestreet.comPlease enable JS and disable any ad blocker\",\n",
    "    \"wsj.comPlease enable JS and disable any ad blocker\",\n",
    "    \"Access Denied Access Denied You don't have permission to access\",\n",
    "    \"Access to this page has been denied\",\n",
    "    \"Sorry! Temporarily Unavailable Sorry, this page is temporarily unavailable for technical reasons.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 196303\n",
      "Blocked count: 7371\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "blocked_words = [\n",
    "    \"thestreet.comPlease enable JS and disable any ad blocker\",\n",
    "    \"wsj.comPlease enable JS and disable any ad blocker\",\n",
    "    \"Access Denied Access Denied You don't have permission to access\",\n",
    "    \"Access to this page has been denied\",\n",
    "    \"Sorry! Temporarily Unavailable Sorry, this page is temporarily unavailable for technical reasons.\"\n",
    "]\n",
    "\n",
    "# Create a regex pattern from the blocked words\n",
    "blocked_pattern = '|'.join([re.escape(word.lower()) for word in blocked_words])\n",
    "\n",
    "total_count = 0\n",
    "blocked_count = 0\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.fillna('')\n",
    "    total_count += df.shape[0]\n",
    "\n",
    "    # Count rows containing any of the blocked words or empty text\n",
    "    blocked_count += df[\n",
    "        df['text'].str.lower().str.contains(blocked_pattern) | (df['text'].str == '')\n",
    "    ].shape[0]\n",
    "\n",
    "print(f\"Total count: {total_count}\")\n",
    "print(f\"Blocked count: {blocked_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8238, 183964, 0.04478050053271292)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocked_count, total_count, blocked_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/kai/forecasting/summary\"\n",
    "\n",
    "summary_paths = glob(data_dir + \"/*/*_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_idxs = []\n",
    "for i, path in enumerate(summary_paths):\n",
    "    summary = load_text_from(path)\n",
    "    summary = '\\n'.join(summary)\n",
    "    if summary == '':\n",
    "        blank_idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(blank_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for i, s in enumerate(summary_paths) if i in blank_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/data/kai/forecasting/raw_urls'\n",
    "file_names = os.listdir(directory_path)\n",
    "\n",
    "ticker = \"aapl\"\n",
    "df = pd.read_csv(directory_path + f'/{ticker}_text.csv')[::-1]\n",
    "\n",
    "data_dir = \"/data/kai/forecasting/summary\"\n",
    "\n",
    "for idx, date_str in enumerate(df[\"timestamp\"].unique()):\n",
    "    if os.path.exists(f\"{data_dir}/{ticker}_{date_str}_final_summary.txt\"):\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "temp_df = df[\"timestamp\"].value_counts().reset_index()\n",
    "temp_df = temp_df.sort_values(by=\"timestamp\")\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(temp_df['timestamp'], temp_df['count'], marker='o')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Number of URLs per Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of URLs')\n",
    "plt.xticks(temp_df['timestamp'][::50], rotation=45)\n",
    "plt.savefig(\"/data/kai/forecasting/eda_plots/AAPL_urls_per_day.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot \n",
    "temp_df = df[\"timestamp\"].value_counts().reset_index()\n",
    "temp_df = temp_df.sort_values(by=\"timestamp\")[30:]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(temp_df['timestamp'], temp_df['count'], marker='o')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Number of URLs per Day without Outliers')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of URLs')\n",
    "plt.xticks(temp_df['timestamp'][::50], rotation=45)\n",
    "plt.savefig(\"/data/kai/forecasting/eda_plots/AAPL_urls_per_day_without_outliers.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = []\n",
    "all_counts = []\n",
    "for ticker in file_names:\n",
    "    df = pd.read_csv(directory_path + \"/\" + ticker)[::-1]\n",
    "    timestamps = pd.to_datetime(df[\"timestamp\"].unique())\n",
    "    \n",
    "    # dates which are not in the sequence \n",
    "    # are returned\n",
    "    missing_dates = pd.date_range(start=df[\"timestamp\"].iloc[-1], end=df[\"timestamp\"].iloc[0]).difference(timestamps)\n",
    "    missing_counts.append(len(missing_dates))\n",
    "    all_counts.append(len(timestamps))\n",
    "\n",
    "    # if len(missing_dates) < len(timestamps):\n",
    "    #     break\n",
    "    # print(ticker, \"Missing dates:\", missing_dates.shape[0], unique_dates.shape[0], df.shape[0], df['timestamp'].iloc[-1], df['timestamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(missing_counts) / (np.array(all_counts) + np.array(missing_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the ratio of missing to all days\n",
    "ratios = np.array(missing_counts) / (np.array(all_counts) + np.array(missing_counts))\n",
    "\n",
    "# Create a list of tuples (file_name, missing_count, all_count, ratio)\n",
    "data = list(zip(file_names, missing_counts, all_counts, ratios))\n",
    "\n",
    "# Sort the data by all_counts in ascending order\n",
    "sorted_data = sorted(data, key=lambda x: x[2])\n",
    "\n",
    "# Unpack the sorted data\n",
    "sorted_file_names, sorted_missing_counts, sorted_all_counts, sorted_ratios = zip(*sorted_data)\n",
    "\n",
    "# Generate labels\n",
    "labels = [f.replace('_text.csv', '') for f in sorted_file_names]\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the position of the bars on the x-axis\n",
    "r1 = range(len(sorted_missing_counts))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(r1, sorted_missing_counts, color='blue', width=bar_width, edgecolor='grey', label='Missing Counts')\n",
    "plt.bar(r2, sorted_all_counts, color='green', width=bar_width, edgecolor='grey', label='All Counts')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of Missing and All Date Counts')\n",
    "plt.xlabel('Companies', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks([r + bar_width/2 for r in range(len(sorted_missing_counts))], labels, rotation=90)\n",
    "\n",
    "# Add text labels for ratios on top of each bar\n",
    "for i in range(len(sorted_missing_counts)):\n",
    "    plt.text(r1[i], sorted_missing_counts[i] + 1, f'{sorted_ratios[i]:.2f}', ha='center', va='bottom', fontsize=10, color='blue')\n",
    "    # plt.text(r2[i], sorted_all_counts[i] + 1, f'{sorted_ratios[i]:.2f}', ha='center', va='bottom', fontsize=10, color='green')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.savefig(\"/data/kai/forecasting/eda_plots/missing_all_dates.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_text_paths = sorted(glob(\"/data/kai/forecasting/summary/*_raw.txt\"))\n",
    "\n",
    "\n",
    "access_denied_counts = 0\n",
    "total_counts = 0\n",
    "\n",
    "for raw_path in tqdm(raw_text_paths, total=len(raw_text_paths)):\n",
    "    raw_texts = load_text_from(raw_path)\n",
    "    raw_texts = [r for r in raw_texts if r != \"<SEP>\" and r != \"\"]\n",
    "    total_counts += len(raw_texts)\n",
    "    access_denied_counts += sum([\"access\" in text.lower() and \"denied\" in text.lower() for text in raw_texts])\n",
    "    # for i in trange(len(raw_texts)):\n",
    "    #     output = pipe.run_llama([\"I will provide a text that is a raw text data from the internet. Repond with a No if access to the page has been denied and there are not relevant stock information:\", \"```````\" + raw_texts[i] + \"```````\"])\n",
    "    #     access_answers.append(output)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_denied_counts,  total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_text_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.run_llama([\"\", \"what is your name in 10 sentences or less?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = f\"{data_dir}/{ticker}_{date_str}_raw.txt\"\n",
    "\n",
    "raw_texts = load_text_from(raw_path)\n",
    "raw_texts = [r for r in raw_texts if r != \"<SEP>\" and r!= \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ending_prompt = f\"Filter out irrelevant information and provide a concise summary including key numbers, growth trends, and the overall market outlook. Ensure to mention major stock movements, significant economic indicators, and any notable company-specific news. Do not make up false information. \"\n",
    "filter_prompt = \"Keep the query the same, but please avoid any extraneous phrases or commentary such as 'Here is the filtered text' or 'I hope this helps.'\"\n",
    "summary_prompt = f\"You are a helpful assistant that filters and summarizes stock news specifically for company with ticker symbol {ticker}.\"\n",
    "combine_prompt = summary_prompt + \" Combine the following summaries while preserving as much information as you can: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe.run_llama([summary_prompt, raw_texts[2]+summary_ending_prompt]*3, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:  \n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
