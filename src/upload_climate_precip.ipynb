{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "from utils import split_data, convert_to_parquet, combine_window\n",
    "import ast\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/numerical_2021-05-04_2023-12-04.csv\"\n",
    "# Path to the directory containing the CSV files\n",
    "climate_data = pd.read_csv(file_path)\n",
    "df = climate_data[['name', 'datetime', 'temp', 'precip', 'longitude']]\n",
    "\n",
    "result = []\n",
    "# sort the state by longitude from left to right\n",
    "latitude_dict = df.set_index('name')['longitude'].to_dict()\n",
    "sorted_states = sorted(latitude_dict.keys(), key = lambda x: latitude_dict[x])\n",
    "\n",
    "# Group by 'datetime' and create the dictionary for 'temp' for each group\n",
    "for date, group in df.groupby('datetime'):\n",
    "    temp_dict = group.set_index('name')['temp'].to_dict()\n",
    "    precip_dict = group.set_index('name')['precip'].to_dict()\n",
    "    \n",
    "    # sorted_temp = {state: temp_dict[state] for state in sorted_states}\n",
    "    # sorted_precip = {state: precip_dict[state] for state in sorted_states}\n",
    "    # result.append({'datetime': date, 'temp': sorted_temp, 'precip': sorted_precip})\n",
    "    # only for california\n",
    "    cal_temp = {\"California\": temp_dict['California']}\n",
    "    cal_precip = {\"California\": precip_dict['California']}\n",
    "    result.append({'datetime': date, 'temp': cal_temp, 'precip': cal_precip})\n",
    "    \n",
    "    \n",
    "\n",
    "# Create the final DataFrame\n",
    "new_df = pd.DataFrame(result)\n",
    "new_df.to_csv('/home/ubuntu/multimodal/Dataset/Climate-raw/temp_precip_cal.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_of_week(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    day_of_week = date_obj.strftime('%A')\n",
    "    return f\"{date_str} ({day_of_week})\"\n",
    "\n",
    "def collapse_json(data):\n",
    "    if pd.isna(data):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        data = ast.literal_eval(data)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Error parsing JSON string: {data}\")\n",
    "        return \"\"\n",
    "    collapsed_string = \"\"\n",
    "    \n",
    "    for key, values in data.items():\n",
    "        collapsed_string += f\"{key}: \" + \" \".join(values)\n",
    "    collapsed_string = collapsed_string.replace(\"_\", \" \")\n",
    "    return collapsed_string.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    {'Hawaii': 77.4, 'Alaska': 46.8, 'Oregon': 51....\n",
      "4    {'Hawaii': 78.0, 'Alaska': 46.5, 'Oregon': 50....\n",
      "5    {'Hawaii': 77.5, 'Alaska': 45.8, 'Oregon': 57....\n",
      "6    {'Hawaii': 77.9, 'Alaska': 45.9, 'Oregon': 58....\n",
      "7    {'Hawaii': 77.8, 'Alaska': 46.4, 'Oregon': 60....\n",
      "Name: temp, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/summarized_temp_precip_v1.csv\"\n",
    "num_file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/temp_precip.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)   # from 05-01 - 12-01 \n",
    "df_num = pd.read_csv(num_file_path)  # from 05-04 - 12-04\n",
    "\n",
    "df = df.iloc[3:]\n",
    "df_num = df_num.iloc[:-3]\n",
    "\n",
    "df['temp'] = df_num['temp'].apply(ast.literal_eval)\n",
    "df['precip'] = df_num['precip'].apply(ast.literal_eval)\n",
    "df['summary'] = df['summary'].apply(collapse_json)\n",
    "df['Time'] = df['Time'].apply(add_day_of_week)\n",
    "df['summary_temp_precip'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"summary\": x['summary'], \"temperature\": x['temp'], \"precipitation\": x['precip']}), axis=1)\n",
    "df['summary'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"summary\": x['summary']}), axis=1)\n",
    "\n",
    "df['fut_summary'] = df['summary'].shift(-1)\n",
    "df['fut_summary_temp_precip'] = df['summary_temp_precip'].shift(-1)\n",
    "\n",
    "\n",
    "df_temp = df[['summary', 'fut_summary', 'summary_temp_precip', 'fut_summary_temp_precip']]\n",
    "df_temp.to_csv('/home/ubuntu/multimodal/Dataset/Climate/temp_precip.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/multimodal/Dataset/Climate/temp_precip.csv'\n",
    "\n",
    "# Loop through each file and split the data\n",
    "split_data(file_path)  # Adjust the directory path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3 text + number  => text + number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a7ee64b5f643dfb5b2ec334fbe92bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba2580001204b748a4497b7a091cc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b23c4ba63284ea8ad14a39b2a2f7da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dc3e082bf546f5be1e9a7315e51c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd91188fa0b4781b0af353cb99e0c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475b72e879a546cf9e01284cfe508180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6f791dd5654229a381de4378cd267d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04abf097f82a4193b4a79c497614ec88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e3c4f4933b45859fdef507bfc58e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9cef8c8bc4437a9eaf63553236fbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f15fdb356fc4684b9456b147adc8908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6656ded5f1a441ee891317ef8258f815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f620347cd464563b6ab1aaaa08a8392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cf00ce30c749eb8e489c11524bfba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79a9a6d7ba547de850e6b818de99d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c2a1660315438ab170c4f483c8bbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a212bd91d7534a158e7d47b4794ed1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c842ac4d89543c7b8a711fb43b406bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e156342262f4a01bb34bc3441fa8a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ddd99d9ea544379726b390beee84b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ab5a9868444945a2d0bd2ef32a9401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/602 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "window_sizes = [1, 2, 3]\n",
    "\n",
    "def create_mixed_mixed(filename, window_size, unit):\n",
    "    if (filename.startswith('train') or filename.startswith('test') or filename.startswith('val')):\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = f\"{window_size} {unit}\"\n",
    "        else:\n",
    "            window = f\"{window_size} {unit}s\"\n",
    "        example_output = {}\n",
    "        example_output[f\"{unit}_{1 + window_size}\"] = {\"Time\": \"...\", \"summary\": \"...\", \"temprature\": \"...\", \"precipitation\": \"...\"}\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the weather summary, temprature, and precipitation of 50 states for {window}, please predict the next 1 day's temprature, precipitation, and weather summary within a JSON. The example output is {example_output}\"\n",
    "        \n",
    "        df = summaries[['summary_temp_precip', 'fut_summary_temp_precip']].rename(columns={'summary_temp_precip': 'input', 'fut_summary_temp_precip': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        df['pred_output'] = \"Not available\"\n",
    "        # skip the first and last historical_size days\n",
    "        return combine_window(df, window_size, \"day\")\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    dataframe_train = []\n",
    "    dataframe_test = []\n",
    "    dataframe_val = []\n",
    "    for filename in os.listdir(dir):\n",
    "        df = create_mixed_mixed(filename, window_size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "\n",
    "    dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "    token = os.getenv(\"HF_TOKEN\")\n",
    "    # Push the dataset to the Hugging Face Hub\n",
    "    dataset_dict.push_to_hub(f\"Howard881010/climate-{window_size}_day-mixed-mixed-precip\", token=token)\n",
    "\n",
    "    # Load the dataset from Hugging Face Hub\n",
    "    # load_from_huggingface(f\"Howard881010/climate-{window_size}_day-mixed-mixed-cal\", \"mixed-mixed-cal\", f\"{window_size}_day\", \"Climate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4 text => text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c2b9f58fa54f2db0b13e20ff5f7702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4565cfea4f4677b7cfa38e26519117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e687ae38e9b7444592c5d7181ea55ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b63d847d2f4155ad098e012493ae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcf6bc6680d4549b55d023b70f1275e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885a8f02a4d84cec99a8278312c13039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d32c4e4dc2940efa1443e06fdda292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99ce54a2c2a4921a1a4232c303bf934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bda0066df343278ffe173e31903047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fd13bde8554edea01a656ec4a6f8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a3a0f8e42743909073bb0f91ebb04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64457b4a794f4f9fa06b0fee7fd6ce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98502ef553444a390266ebc45061c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fd2ff89af44bcebb955dd47b2bfcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a873750b02f4f44bc90d03083863ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4a85ece1a34ce1a91aacd9066878df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb83701dcee47c18149c33549ba3826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e328e03d3c9f43a789a0a6fa9f8313bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "\n",
    "window_sizes = [1, 2, 3]\n",
    "\n",
    "def create_text_text(filename, window_size, unit):\n",
    "    if (filename.startswith('train') or filename.startswith('test') or filename.startswith('val')):\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = f\"{window_size} {unit}\"\n",
    "        else:\n",
    "            window = f\"{window_size} {unit}s\"\n",
    "        example_output = {}\n",
    "        example_output[f\"{unit}_{1+window_size}\"] = {\"Time\": \"...\", \"summary\": \"...\"}\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the weather summary for {window}, please predict the next 1 day's weather summary within a JSON. The example output is {example_output}\"\n",
    "        \n",
    "        df = summaries[['summary', 'fut_summary']].rename(columns={'summary': 'input', 'fut_summary': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        df['pred_output'] = \"Not available\"\n",
    "        # skip the first and last historical_size days\n",
    "        return combine_window(df, window_size, \"day\")\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    dataframe_train = []\n",
    "    dataframe_test = []\n",
    "    dataframe_val = []\n",
    "    for filename in os.listdir(dir):\n",
    "        df = create_text_text(filename, window_size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "            \n",
    "    dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "    token = os.getenv(\"HF_TOKEN\")\n",
    "    # Push the dataset to the Hugging Face Hub\n",
    "    dataset_dict.push_to_hub(f\"Howard881010/climate-{window_size}_day-text-text-precip\", token=token)\n",
    "\n",
    "    # Load the dataset from Hugging Face Hub\n",
    "    # load_from_huggingface(f\"Howard881010/climate-{window_size}_day-text-text\", \"text-text\", f\"{window_size}_day\", \"Climate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e199943dca492691a51c27665d22f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5217999eef429191d6093f243c5fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2a92720daf424ea4473da70e3ba6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bfe71fef2c41e1a897a7d7412c7704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f66c0d7bd743dbaaf84437eb1e34f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27ad8228205440e934926e75753790a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976db48c6f9c4ad9821f5c3f029d90db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Howard881010/climate-precip/commit/fed5be6872ede6a505d31a77ecf57eb167237335', commit_message='Upload dataset', commit_description='', oid='fed5be6872ede6a505d31a77ecf57eb167237335', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    for size in range(1, window_size+1):\n",
    "        df1 = create_text_text(filename, size, \"day\")\n",
    "        df2 = create_mixed_mixed(filename, size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df1)\n",
    "            dataframe_test.append(df2)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df1)\n",
    "            dataframe_train.append(df2)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df1)\n",
    "            dataframe_val.append(df2)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/climate-precip\", token=token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmforcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
