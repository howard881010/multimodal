{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "from utils import split_data, convert_to_parquet, combine_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/numerical_2021-05-04_2023-12-04.csv\"\n",
    "# Path to the directory containing the CSV files\n",
    "climate_data = pd.read_csv(file_path)\n",
    "df = climate_data[['name', 'datetime', 'temp', 'longitude']]\n",
    "\n",
    "result = []\n",
    "# sort the state by longitude from left to right\n",
    "latitude_dict = df.set_index('name')['longitude'].to_dict()\n",
    "sorted_states = sorted(latitude_dict.keys(), key = lambda x: latitude_dict[x])\n",
    "\n",
    "# Group by 'datetime' and create the dictionary for 'temp' for each group\n",
    "for date, group in df.groupby('datetime'):\n",
    "    temp_dict = group.set_index('name')['temp'].to_dict()\n",
    "    \n",
    "    sorted_temp = {state: temp_dict[state] for state in sorted_states}\n",
    "    result.append({'datetime': date, 'temp': sorted_temp})\n",
    "    # only for california\n",
    "    # cal_temp = {\"California\": temp_dict['California']}\n",
    "    # result.append({'datetime': date, 'temp': cal_temp})\n",
    "    \n",
    "    \n",
    "\n",
    "# Create the final DataFrame\n",
    "new_df = pd.DataFrame(result)\n",
    "new_df.to_csv('/home/ubuntu/multimodal/Dataset/Climate-raw/procoess_num_cal.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_of_week(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    day_of_week = date_obj.strftime('%A')\n",
    "    return f\"{date_str} ({day_of_week})\"\n",
    "\n",
    "def collapse_json(data):\n",
    "    collapsed_string = \"\"\n",
    "    data = ast.literal_eval(data)\n",
    "    for key, values in data.items():\n",
    "        collapsed_string += f\"{key}: \" + \" \".join(values)\n",
    "    collapsed_string = collapsed_string.replace(\"_\", \" \")\n",
    "    return collapsed_string.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    {\"Time\": \"2021-05-04 (Tuesday)\", \"temperature\"...\n",
      "4    {\"Time\": \"2021-05-05 (Wednesday)\", \"temperatur...\n",
      "5    {\"Time\": \"2021-05-06 (Thursday)\", \"temperature...\n",
      "6    {\"Time\": \"2021-05-07 (Friday)\", \"temperature\":...\n",
      "7    {\"Time\": \"2021-05-08 (Saturday)\", \"temperature...\n",
      "Name: temp, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/summarized_temperature_v1.csv\"\n",
    "num_file_path = \"/home/ubuntu/multimodal/Dataset/Climate-raw/procoess_num.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)   # from 05-01 - 12-01 \n",
    "df_num = pd.read_csv(num_file_path)  # from 05-04 - 12-04\n",
    "\n",
    "df = df.iloc[3:]\n",
    "df_num = df_num.iloc[:-3]\n",
    "\n",
    "df['temp'] = df_num['temp'].apply(ast.literal_eval)\n",
    "\n",
    "df['fut_temp'] = df['temp'].shift(-1)\n",
    "df['summary'] = df['summary'].apply(collapse_json)\n",
    "df['fut_summary'] = df['summary'].shift(-1)\n",
    "df['Time'] = df['Time'].apply(add_day_of_week)\n",
    "df['fut_Time'] = df['Time'].shift(-1)\n",
    "df['summary_temp'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"summary\": x['summary'], \"temperature\": x['temp']}), axis=1)\n",
    "\n",
    "df['summary_temp'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"summary\": x['summary'], \"temperature\": x['temp']}), axis=1)\n",
    "df['fut_summary_temp'] = df.apply(lambda x: json.dumps({\"Time\": x['fut_Time'], \"summary\": x['fut_summary'], \"temperature\": x['fut_temp']}), axis=1)\n",
    "df['temp'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"temperature\": x['temp']}), axis=1)\n",
    "df['fut_temp'] = df.apply(lambda x: json.dumps({\"Time\": x['fut_Time'], \"temperature\": x['fut_temp']}), axis=1)\n",
    "df['summary'] = df.apply(lambda x: json.dumps({\"Time\": x['Time'], \"summary\": x['summary']}), axis=1)\n",
    "df['fut_summary'] = df.apply(lambda x: json.dumps({\"Time\": x['fut_Time'], \"summary\": x['fut_summary']}), axis=1)\n",
    "\n",
    "print(df['temp'].head(5))\n",
    "\n",
    "\n",
    "df_temp = df[['fut_summary', 'fut_temp', 'temp', 'summary', 'fut_summary_temp', 'summary_temp']]\n",
    "df_temp.to_csv('/home/ubuntu/multimodal/Dataset/Climate/temp.csv', index=False)\n",
    "\n",
    "file_path = '/home/ubuntu/multimodal/Dataset/Climate/temp.csv'\n",
    "\n",
    "# Loop through each file and split the data\n",
    "split_data(file_path)  # Adjust the directory path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/multimodal/Dataset/Climate/temp_cal.csv'\n",
    "\n",
    "# Loop through each file and split the data\n",
    "split_data(file_path)  # Adjust the directory path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3 text + number  => text + number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801515375ba4433b859cc6575f995a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2befe098798c484fa23e8e0a147bc172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ee4815d7ab4b85b43d5d4e4f8d8891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851a05717cef4db29c5b2c266c60ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2523c1ebc8b3462cb6f6c000f36cd33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b6dd7b9b3454e890b43e6c8ab91be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8663c73fd4aa4068beb1b8e7f70f3cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ede74569e4fd8a6b33c79f24af0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59b61ccaf72426c80af177dda4dfb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9196b8d5a4839b30a449b0bc4e272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed77aff58b548c3a47fc44a8269acba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e092ebccda49deb1d9a87ba5c3d565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fb6c82c9e84e06856186075301453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b3e9dfd3b4705b09a40ed9d970337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bea33584ed141ba9bc6496214af9f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044620bfd701430391b1376dc8440431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7d191a8184f5f87d942b9535a3710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5150f8d5757c41f1948a1982c5c60193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f74efb9a0e4abca6a3ca3746dd168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a640da1cece142f98f7ca83d2cee9364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49e72004db14d57b870c8d8d1e1eb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccbc174c6924cfb99cd1258ac3647eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741bd266623c439f92da8b95195526c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36006c5ed36947f19fc94140da90173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cba83b07a5e4ec48c46a3a9809c3f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872fb17ef0174cf7aee07fada50c7d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f6db981a904ad9b4ee9b7770bf661b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "window_sizes = [1, 2, 3]\n",
    "\n",
    "def create_mixed_mixed(filename, window_size, unit):\n",
    "    if (filename.startswith('train') or filename.startswith('test') or filename.startswith('val')):\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = f\"{window_size} {unit}\"\n",
    "        else:\n",
    "            window = f\"{window_size} {unit}s\"\n",
    "        example_output = {}\n",
    "        example_output[f\"{unit}_{1 + window_size}\"] = {\"Time\": \"...\", \"summary\": \"...\", \"temprature\": \"...\"}\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the weather summary and the temprature of california for {window}, please predict the next 1 day's temprature of 50 states and weather summary within a JSON. The example output is {example_output}\"\n",
    "        \n",
    "        df = summaries[['summary_temp', 'fut_summary_temp']].rename(columns={'summary_temp': 'input', 'fut_summary_temp': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        df['pred_output'] = \"Not available\"\n",
    "        # skip the first and last historical_size days\n",
    "        return combine_window(df, window_size, \"day\")\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    dataframe_train = []\n",
    "    dataframe_test = []\n",
    "    dataframe_val = []\n",
    "    for filename in os.listdir(dir):\n",
    "        df = create_mixed_mixed(filename, window_size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "\n",
    "    dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "    token = os.getenv(\"HF_TOKEN\")\n",
    "    # Push the dataset to the Hugging Face Hub\n",
    "    dataset_dict.push_to_hub(f\"Howard881010/climate-{window_size}_day-mixed-mixed-cal\", token=token)\n",
    "\n",
    "    # Load the dataset from Hugging Face Hub\n",
    "    # load_from_huggingface(f\"Howard881010/climate-{window_size}_day-mixed-mixed-cal\", \"mixed-mixed-cal\", f\"{window_size}_day\", \"Climate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4 text => text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bfd2dd6ab5446da87041b76d03bfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5fe528993d4e518c14a3ccb8d8ef5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5265cfe646144ed8af28c3eb0580402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4485dfd02040318f937675c8a2e383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f4b5e5d63c4084831f462c53b24d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20667e029644ae9ac886d05054eda44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc11ecd77cd4844a46c9fd7f994d6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ddc817278f41f6a3a15ba8b0b84d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b3012f7a214e4eaa2f2fb2d7ce7542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba17da301fc40d8be9f2326f2bfb7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed747e55f0a4655be4d512d0a4fa7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7318f6bc260b43c187378e70794a39cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c72fc9c5b84eb6a9deb6296836abfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775cd0faedd047bca630d86a05044e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e004a8f33b4637b9f9ab9b77c981ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6acd90a8c134556a02849998f62526c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20facef297a84c9782b3c72635838734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02ac818c29f453f8409f17707d5c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5324d75f9314cd7bcbbbb4b745fa99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74661a1d44fb4fa5826442a5785376c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee373068850414d8de8fbb492cc431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f107860df4748a8a1769c61273efb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5503cd1dd4053801608ced64a38ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bad8e1b0364d7188aada81a83e2a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417854a0503340dba29533bf91a91291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67e145f30a64619a8c682524304c8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3e3fd58f1648f695f4a9eee285b058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "\n",
    "window_sizes = [1, 2, 3]\n",
    "\n",
    "def create_text_text(filename, window_size, unit):\n",
    "    if (filename.startswith('train') or filename.startswith('test') or filename.startswith('val')):\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = f\"{window_size} {unit}\"\n",
    "        else:\n",
    "            window = f\"{window_size} {unit}s\"\n",
    "        example_output = {}\n",
    "        example_output[f\"{unit}_{1+window_size}\"] = {\"Time\": \"...\", \"summary\": \"...\"}\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the weather summary for {window}, please predict the next 1 day's weather summary within a JSON. The example output is {example_output}\"\n",
    "        \n",
    "        df = summaries[['summary', 'fut_summary']].rename(columns={'summary': 'input', 'fut_summary': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        df['pred_output'] = \"Not available\"\n",
    "        # skip the first and last historical_size days\n",
    "        return combine_window(df, window_size, \"day\")\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    dataframe_train = []\n",
    "    dataframe_test = []\n",
    "    dataframe_val = []\n",
    "    for filename in os.listdir(dir):\n",
    "        df = create_text_text(filename, window_size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "            \n",
    "    dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "    token = os.getenv(\"HF_TOKEN\")\n",
    "    # Push the dataset to the Hugging Face Hub\n",
    "    dataset_dict.push_to_hub(f\"Howard881010/climate-{window_size}_day-text-text-cal\", token=token)\n",
    "\n",
    "    # Load the dataset from Hugging Face Hub\n",
    "    # load_from_huggingface(f\"Howard881010/climate-{window_size}_day-text-text\", \"text-text\", f\"{window_size}_day\", \"Climate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87857e5f70574561987f3c122f6c368d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9252db7124df414f83059b16c574b3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588f551a63c24ac38043b05a9c7a6419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d1875e02eb486181c0cc2e34f2e1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af43abc7e9204814b522b502e66efd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634ac2f5bc23427e8de27df3a5cec49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7bd94bfa2b485fb024f3ed23a5501c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18f303361134a63bd723915d6f207bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da27c4bee45548768109fbb896cd5d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84486982e96464c9bedb63de29babb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Howard881010/climate-cal/commit/72a27e86ebaef59cb116afec08aedc07ec3a8e5a', commit_message='Upload dataset', commit_description='', oid='72a27e86ebaef59cb116afec08aedc07ec3a8e5a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '../Dataset/Climate'\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    for size in range(1, window_size+1):\n",
    "        df1 = create_text_text(filename, size, \"day\")\n",
    "        df2 = create_mixed_mixed(filename, size, \"day\")\n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df1)\n",
    "            dataframe_test.append(df2)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df1)\n",
    "            dataframe_train.append(df2)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df1)\n",
    "            dataframe_val.append(df2)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/climate-cal\", token=token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmforcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
