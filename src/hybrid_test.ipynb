{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/multimodal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts.models import NLinearModel\n",
    "from darts import TimeSeries\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from loguru import logger\n",
    "from utils import open_record_directory, open_result_directory, rmse, nmae\n",
    "from finance_multimodal import getLLMTIMERMSE\n",
    "from transformers import set_seed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model_inference(summaries):\n",
    "\n",
    "    # Set float32 matmul precision to utilize Tensor Cores\n",
    "    torch.set_float32_matmul_precision('high')  # You can also use 'medium' for less precision but potentially higher performance\n",
    "\n",
    "    # Load pre-trained model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Use DataParallel to wrap the model if multiple GPUs are available\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using {} GPUs\".format(torch.cuda.device_count()))\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Move model to the available GPU(s)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    model = model.to(device)\n",
    "    print(type(summaries[0]))\n",
    "\n",
    "    # Tokenize summaries\n",
    "    inputs = tokenizer(summaries, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 2\n",
    "\n",
    "    # Function to get batches\n",
    "    def get_batches(input_ids, attention_mask, batch_size):\n",
    "        for i in range(0, len(input_ids), batch_size):\n",
    "            yield input_ids[i:i + batch_size], attention_mask[i:i + batch_size]\n",
    "\n",
    "    # Create batches\n",
    "    batches = list(get_batches(input_ids, attention_mask, batch_size))\n",
    "\n",
    "    # Perform inference on each batch and collect pooled outputs\n",
    "    pooled_outputs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in batches:\n",
    "            input_ids_batch, attention_mask_batch = batch\n",
    "            input_ids_batch = input_ids_batch.to(device)\n",
    "            attention_mask_batch = attention_mask_batch.to(device)\n",
    "            outputs = model(input_ids_batch, attention_mask=attention_mask_batch)\n",
    "            pooled_output = outputs.pooler_output.cpu().numpy()\n",
    "            pooled_outputs.append(pooled_output)\n",
    "\n",
    "    pooled_outputs = np.vstack(pooled_outputs)  # Shape: (num_samples, 768)\n",
    "\n",
    "    return pooled_outputs\n",
    "\n",
    "\n",
    "def nlinear_darts(train_input, train_output, test_input, historcial_window_size,train_embedding=None, test_embedding=None):\n",
    "    # Convert to TimeSeries object required by Darts\n",
    "    train_series = TimeSeries.from_values(train_input)\n",
    "    train_output_series = TimeSeries.from_values(train_output)\n",
    "    if train_embedding is not None:\n",
    "        train_past_covariates = TimeSeries.from_values(train_embedding)\n",
    "        test_past_covariates = TimeSeries.from_values(test_embedding)\n",
    "    else:\n",
    "        train_past_covariates = None\n",
    "        test_past_covariates = None\n",
    "    \n",
    "    # Define and train the NLinearModel model\n",
    "    model_NLinearModel = NLinearModel(input_chunk_length=historcial_window_size, output_chunk_length=historcial_window_size, n_epochs=100, pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": 1}, )\n",
    "    model_NLinearModel.fit(train_series, past_covariates=train_past_covariates, future_covariates=train_output_series)\n",
    "\n",
    "    pred_value = []\n",
    "    test = np.array([])\n",
    "    # Make predictions\n",
    "    for i in range(len(test_input)):\n",
    "        test = np.append(test, test_input[i])\n",
    "        test_series = TimeSeries.from_values(test)\n",
    "        print(\"input: \", test_series)\n",
    "        predictions = model_NLinearModel.predict(n=historcial_window_size, series=test_series, past_covariates=test_past_covariates).all_values().flatten().tolist()\n",
    "        str_res = ' '.join([str(round(num,2)) for num in predictions])\n",
    "        print(\"Prediction: \" + str_res)\n",
    "        pred_value.append(str_res)\n",
    "    print(pred_value)\n",
    "    \n",
    "    return pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
