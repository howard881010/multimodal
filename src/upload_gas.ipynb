{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datasets import DatasetDict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ubuntu/multimodal/Dataset/Gas-raw/West_Coast_fact.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['fut_price'] = df['Weekly West Coast All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)'].shift(-1)\n",
    "df['fut_summary'] = df['text']\n",
    "df['summary'] = df['text'].shift(1)\n",
    "\n",
    "df['time_period'] = df.apply(lambda x: x['start_date'] + \" - \" + x['end_date'], axis=1)\n",
    "df['fut_time_period'] = df['time_period'].shift(-1)\n",
    "# df = df.rename(columns={'text': 'summary'})\n",
    "df = df.rename(columns={'Weekly West Coast All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)': 'price'})\n",
    "df['summary_price'] = df.apply(lambda x: json.dumps({\"time-period\": x['time_period'], \"summary\": x['summary'], \"gas_price\": x['price']}), axis=1)\n",
    "df['fut_summary_price'] = df.apply(lambda x: json.dumps({\"time-period\": x['fut_time_period'], \"summary\": x['fut_summary'], \"gas_price\": x['fut_price']}), axis=1)\n",
    "df['price'] = df.apply(lambda x: json.dumps({\"time-period\": x['time_period'], \"gas_price\": x['price']}), axis=1)\n",
    "df['fut_price'] = df.apply(lambda x: json.dumps({\"time-period\": x['fut_time_period'], \"gas_price\": x['fut_price']}), axis=1)\n",
    "df['summary'] = df.apply(lambda x: json.dumps({\"time-period\": x['time_period'], \"summary\": x['summary']}), axis=1)\n",
    "df['fut_summary'] = df.apply(lambda x: json.dumps({\"time-period\": x['fut_time_period'], \"summary\": x['fut_summary']}), axis=1)\n",
    "\n",
    "# print(df.head(5))\n",
    "df.to_csv('/home/ubuntu/multimodal/Dataset/Gas/West_Coast_fact.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(file_path, train_ratio=0.8, validation_ratio=0.1, test_ratio=0.1):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate the validation and test sizes\n",
    "    val_size = validation_ratio / (test_ratio + validation_ratio)\n",
    "    \n",
    "    # Split the data into train and temporary datasets\n",
    "    train_data, temp_data = train_test_split(data, test_size=(1 - train_ratio), random_state=42, shuffle=False)\n",
    "    \n",
    "    # Split the temporary dataset into validation and test datasets\n",
    "    validation_data, test_data = train_test_split(temp_data, test_size=val_size, random_state=42, shuffle=False)\n",
    "    \n",
    "    # Save the datasets\n",
    "    \n",
    "    dir = file_path.split('/')[:-1]\n",
    "    dir = '/'.join(dir)\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    train_data.to_csv(f'{dir}/train_{file_name}', index=False)\n",
    "    validation_data.to_csv(f'{dir}/val_{file_name}', index=False)\n",
    "    test_data.to_csv(f'{dir}/test_{file_name}', index=False)\n",
    "\n",
    "# List of your CSV files\n",
    "dir = '/home/ubuntu/multimodal/Dataset/Gas/fact_only'\n",
    "\n",
    "# Loop through each file and split the data\n",
    "for filename in os.listdir(dir):\n",
    "    if not filename.startswith(\"train\") and not filename.startswith(\"test\") and not filename.startswith(\"val\"):\n",
    "        path = os.path.join(dir, filename)\n",
    "        split_data(path)  # Adjust the directory path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_parquet(dataframe_test, dataframe_train, dataframe_val):\n",
    "    train = pd.concat(dataframe_train)\n",
    "    test = pd.concat(dataframe_test)\n",
    "    val = pd.concat(dataframe_val)\n",
    "\n",
    "    train_path = '../parquet_dir/train_finance.parquet'\n",
    "    test_path = '../parquet_dir/test_finance.parquet'\n",
    "    val_path = '../parquet_dir/val_finance.parquet'\n",
    "\n",
    "    train.to_parquet(train_path, engine='pyarrow')\n",
    "    test.to_parquet(test_path, engine='pyarrow')\n",
    "    val.to_parquet(val_path, engine='pyarrow')\n",
    "    # Load the dataset\n",
    "    train_dataset = load_dataset('parquet', data_files=train_path, split='train')\n",
    "    test_dataset = load_dataset('parquet', data_files=test_path, split='train')\n",
    "    val_dataset = load_dataset('parquet', data_files=val_path, split = 'train')\n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': val_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_huggingface(dataset_path, case, units):\n",
    "    dataset = load_dataset(dataset_path)\n",
    "\n",
    "    if not os.path.exists(f\"../Data/Gas/{units}/{case}\"):\n",
    "        os.makedirs(f\"../Data/Gas/{units}/{case}\")\n",
    "\n",
    "# Access the train split\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        train_dataset = dataset[split]\n",
    "\n",
    "        # Convert the dataset to a Pandas DataFrame\n",
    "        df = train_dataset.to_pandas()\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f\"../Data/Gas/{units}/{case}/{split}_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_window(df, window_size, unit):\n",
    "    json_data = []\n",
    "    end_index = len(df) - 2 * window_size + 1\n",
    "\n",
    "\n",
    "    for i in range(end_index):\n",
    "        combined_input = {}\n",
    "        combine_output = {}\n",
    "        \n",
    "        for j in range(window_size):\n",
    "            input_key = f\"{unit}_{j+1}\"\n",
    "            output_key = f\"{unit}_{j+window_size+1}\"\n",
    "            combined_input[input_key] = json.loads(df.iloc[i + j]['input'])\n",
    "            combine_output[output_key] = json.loads(df.iloc[i + j + window_size - 1]['output'])\n",
    "        combine_json = {\n",
    "            \"input\": json.dumps(combined_input),\n",
    "            \"output\": json.dumps(combine_output),\n",
    "            \"instruction\": df.iloc[i]['instruction']\n",
    "        }\n",
    "        json_data.append(combine_json)\n",
    "    \n",
    "    json_df = pd.DataFrame(json_data)\n",
    "    return json_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3 text + number  => text + number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba89494f194e3b81e6fcf1249f8065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c344b403f64d6caec3cec3734a31f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1c83e24d024c1088ab11b5ecb2df72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca18bda8744e5bbdf98c26cd98c057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d766991fad944e4ba8ef77296d2a0148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4837b635a44545aa0c3888ad731a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51205508a362458182c4de04c75d36e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81540fe934074678b5f116e03cb1f646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffc6b6456ad4883b04a10441aa7e090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c929eb893dc745b79a81ffa1607dac90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432279a625d546a5a90e4f0b70ea9f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015d697657e64714bdff5dd4d6aad257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/290k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f163d5381da44b48b0b807717fa989a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a174d8a382a04128b81ec08d87bfa179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/43.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f146174046b45658af6b1d5362f190f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d945f13f238847c8a6bbe47c5eec00f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aed60ca9d542bb800be69b92750e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Gas/fact_only'\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    if filename.startswith('train') or filename.startswith('test') or filename.startswith('val'):\n",
    "        split = filename.split('_')[0]\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = \"1 week\"\n",
    "        else:\n",
    "            window = f\"{window_size} weeks\"\n",
    "        example_output = {}\n",
    "        for i in range(window_size):\n",
    "            example_output[f\"week_{i+1+window_size}\"] = {\"time-period\": \"<time-period>\", \"summary\": \"<summary>\", \"gas_price\": \"<gas_price>\"}\n",
    "        # example_output = \"{\\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}, ... \\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}}\"\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the summary and the gas price for {window}, please predict the next {window}'s gas price and summary in json format. And ouput only the json data, the response should only contain {example_output}\"\n",
    "\n",
    "        df = summaries[['summary_price', 'fut_summary_price']].rename(columns={'summary_price': 'input', 'fut_summary_price': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        # skip the first and last historical_size days\n",
    "    df = combine_window(df, window_size, \"week\")\n",
    "    \n",
    "    if filename.startswith('test'):\n",
    "        dataframe_test.append(df)\n",
    "    elif filename.startswith('train'):\n",
    "        dataframe_train.append(df)\n",
    "    elif filename.startswith('val'):\n",
    "        dataframe_val.append(df)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/gas-{window_size}_week-mixed-mixed-fact\", token=token)\n",
    "\n",
    "# Load the dataset from Hugging Face Hub\n",
    "load_from_huggingface(f\"Howard881010/gas-{window_size}_week-mixed-mixed-fact\", \"mixed-mixed-fact\", f\"{window_size}_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4 text => text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf65fe453bd423bb22de9a8a3793bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27de5305a03d4718b75f24c266af4a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1495a1c7f7c14d55a37f55552a57774e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08944188aebf4666a3907f0f002f2534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7053922c8af24a96b09b7f38012b5086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deab1995294416183d119557a1bc620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0c4999a7e347d9aea905dc3c346b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bda3fe724c4322a30a80ac4d60db89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9529534aa4d4d4f90b049a464cb5882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542af7597bc84a7783f33ef7f3200e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016ab0d7c3fe43c0873284cce1120ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24173de7030147de858e6a073946dcc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/270k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b7fc359d9545d296f1d5e640f2a34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/38.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a8fbe0a33b462baeb597824c0d97b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a8ff0da4024c44acc4605ce7edf736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc453faea87a410da18a4abfd29d86a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fad983917fd46e59175954b63ea547b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Gas/fact_only'\n",
    "# case 1: number -> number\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    if filename.startswith('train') or filename.startswith('test') or filename.startswith('val'):\n",
    "        split = filename.split('_')[0]\n",
    "        path = os.path.join(dir, filename)\n",
    "        summaries = pd.read_csv(path)\n",
    "\n",
    "        if window_size == 1:\n",
    "            window = \"1 week\"\n",
    "        else:\n",
    "            window = f\"{window_size} weeks\"\n",
    "        example_output = {}\n",
    "        for i in range(window_size):\n",
    "            example_output[f\"week_{i+1+window_size}\"] = {\"time-period\": \"<time-period>\", \"summary\": \"<summary>\"}\n",
    "        # example_output = \"{\\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}, ... \\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}}\"\n",
    "        example_output = json.dumps(example_output)\n",
    "        instruction = f\"Given the summary and time period for {window},please predict next {window} summary in json format. And ouput only the json data, the response should only contain {example_output}\"\n",
    "\n",
    "        df = summaries[['summary', 'fut_summary']].rename(columns={'summary': 'input', 'fut_summary': 'output'})\n",
    "        df['instruction'] = instruction\n",
    "        # skip the first and last historical_size days\n",
    "    df = combine_window(df, window_size, \"week\")\n",
    "    \n",
    "    if filename.startswith('test'):\n",
    "        dataframe_test.append(df)\n",
    "    elif filename.startswith('train'):\n",
    "        dataframe_train.append(df)\n",
    "    elif filename.startswith('val'):\n",
    "        dataframe_val.append(df)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/gas-{window_size}_week-text-text-fact\", token=token)\n",
    "\n",
    "# Load the dataset from Hugging Face Hub\n",
    "load_from_huggingface(f\"Howard881010/gas-{window_size}_week-text-text-fact\", \"text-text-fact\", f\"{window_size}_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd01016fdda4ceda254b4b6cc75844c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865f9557515d41e9a68b29183f6df003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a7a737d7dd43beafbda9c555e95f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4ae77d4ef6485699ca8044be8cf869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d0ab5f07d34370b5f1ae37fcf6903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0be3dc67974bb7ae174c0487591f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b129b08d14deb95fdd02650580ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4cd2c484ca4508aad7c4b0e2a951f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d698f9b779d460da3662d99b0c663cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c982842ae640bd9c4049a55ab45d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/606 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def4213ac4b149e587ab4647f2b29f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/670k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5baeb0ca3ef94f93a3fc4369b75444bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d0755475804290950fd9a0d1d271ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1de7eec48e4a16af5e102cac78147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3430e92c2638467a89e9ac718ecc5b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c20a8c2c4d437b8d85406e5a9b3fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Gas/fact_only'\n",
    "# case 1: number -> number\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    for size in range(1, window_size+1):\n",
    "        if filename.startswith('train') or filename.startswith('test') or filename.startswith('val'):\n",
    "            split = filename.split('_')[0]\n",
    "            path = os.path.join(dir, filename)\n",
    "            summaries = pd.read_csv(path)\n",
    "\n",
    "            if size == 1:\n",
    "                window = \"1 week\"\n",
    "            else:\n",
    "                window = f\"{size} weeks\"\n",
    "            example_output = {}\n",
    "            for i in range(size):\n",
    "                example_output[f\"week_{i+1+size}\"] = {\"time-period\": \"<time-period>\", \"summary\": \"<summary>\"}\n",
    "            # example_output = \"{\\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}, ... \\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}}\"\n",
    "            example_output = json.dumps(example_output)\n",
    "            instruction = f\"Given the summary and time period for {window},please predict next {window} summary in json format. And ouput only the json data, the response should only contain {example_output}\"\n",
    "\n",
    "            df = summaries[['summary', 'fut_summary']].rename(columns={'summary': 'input', 'fut_summary': 'output'})\n",
    "            df['instruction'] = instruction\n",
    "            # skip the first and last historical_size days\n",
    "        df = combine_window(df, size, \"week\")\n",
    "        \n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/gas-week-text-text-fact\", token=token)\n",
    "\n",
    "# Load the dataset from Hugging Face Hub\n",
    "load_from_huggingface(f\"Howard881010/gas-week-text-text-fact\", \"text-text-fact\", f\"week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272db037ee984a8da49e35bff21bad12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5f0963dcbb4c3b813414ff46ba0d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ab8cf4cda4911812c8dded0e09355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5964edbf01420095b8fb88ae2a1bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f86d3deb33e4379871b045ad9d6e0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cf3565d960425b8b11e99d67cd4f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c4e4c9ede2418693aa2542f007dcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75baca4d37a048f1b50099f204be63db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af119ae8b62441fa94dbb681fc2e3180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44069b27e3dc473da58da58afffa491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/606 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2d1ac95aab457191c8e46e0cd14f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/716k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546416f01d454ce4b5939f2a6e5a9fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/78.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9e0d19d54b4705a1da20582efcd6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/80.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec09bf757a148ceaede1f56853d6b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c2404b7bc9496e8895fe2852478745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b253c50a8042e88bed042d005ffa11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = '../Dataset/Gas/fact_only'\n",
    "dataframe_train = []\n",
    "dataframe_test = []\n",
    "dataframe_val = []\n",
    "window_size = 3\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir):\n",
    "    for size in range(1, window_size+1):\n",
    "        if filename.startswith('train') or filename.startswith('test') or filename.startswith('val'):\n",
    "            split = filename.split('_')[0]\n",
    "            path = os.path.join(dir, filename)\n",
    "            summaries = pd.read_csv(path)\n",
    "\n",
    "            if size == 1:\n",
    "                window = \"1 week\"\n",
    "            else:\n",
    "                window = f\"{size} weeks\"\n",
    "            example_output = {}\n",
    "            for i in range(size):\n",
    "                example_output[f\"week_{i+1+size}\"] = {\"time-period\": \"<time-period>\", \"summary\": \"<summary>\", \"gas_price\": \"<gas_price>\"}\n",
    "            # example_output = \"{\\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}, ... \\\"week_n\\\":{\\\"time-period\\\": <time-period>,\\\"summary\\\": <summary>}}\"\n",
    "            example_output = json.dumps(example_output)\n",
    "            instruction = f\"Given the summary and the gas price for {window}, please predict the next {window}'s gas price and summary in json format. And ouput only the json data, the response should only contain {example_output}\"\n",
    "\n",
    "            df = summaries[['summary_price', 'fut_summary_price']].rename(columns={'summary_price': 'input', 'fut_summary_price': 'output'})\n",
    "            df['instruction'] = instruction\n",
    "            # skip the first and last historical_size days\n",
    "        df = combine_window(df, size, \"week\")\n",
    "        \n",
    "        if filename.startswith('test'):\n",
    "            dataframe_test.append(df)\n",
    "        elif filename.startswith('train'):\n",
    "            dataframe_train.append(df)\n",
    "        elif filename.startswith('val'):\n",
    "            dataframe_val.append(df)\n",
    "        \n",
    "dataset_dict = convert_to_parquet(dataframe_test, dataframe_train, dataframe_val)\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "# Push the dataset to the Hugging Face Hub\n",
    "dataset_dict.push_to_hub(f\"Howard881010/gas-week-mixed-mixed-fact\", token=token)\n",
    "\n",
    "# Load the dataset from Hugging Face Hub\n",
    "load_from_huggingface(f\"Howard881010/gas-week-mixed-mixed-fact\", \"mixed-mixed-fact\", f\"week\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmforcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
